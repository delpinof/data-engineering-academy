{"paragraphs":[{"text":"%md\n# Iterations and matrix multiplication\n\nWelcome to the notebook with the exercises for the second session. You’re well on your way to obtain the Wizeline Certification for Big Data Engineering with Spark!\n\nIf you have any feedback about our courses, email us at academy@wizeline.com or use the Academy Slack channel.","dateUpdated":"2018-08-16T22:04:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Iterations and matrix multiplication</h1>\n<p>Welcome to the notebook with the exercises for the second session. You’re well on your way to obtain the Wizeline Certification for Big Data Engineering with Spark!</p>\n<p>If you have any feedback about our courses, email us at <a href=\"mailto:&#97;c&#x61;&#100;e&#x6d;&#x79;@&#119;&#105;&#122;e&#108;&#x69;n&#x65;&#x2e;com\">&#97;c&#x61;&#100;e&#x6d;&#x79;@&#119;&#105;&#122;e&#108;&#x69;n&#x65;&#x2e;com</a> or use the Academy Slack channel.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588838_420763624","id":"20180815-184319_767984790","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:434","user":"anonymous","dateFinished":"2018-08-16T22:04:49+0000","dateStarted":"2018-08-16T22:04:49+0000"},{"text":"%md\n\n## Exercise #1 - HDFS User Interface\nIn this exercise, you will create a second SSH tunnel to connect to the HDFS UI. In this UI, you can see the details of the distributed storage system that your current cluster is using.\n\nTo create a new SSH tunnel, follow the next steps:\n1. On the `Google Cloud Shell` used to execute this Zeppelin instance, click the `+` sign to **Add cloud shell session**.\n2. To create the tunnel, enter the following command: \n`gcloud compute ssh --project data-castle-bravo --zone us-central1-a --ssh-flag=\"-L 9870:localhost:9870\" de-training-<user-name>-m`\nMake sure to replace `<user-name>` with your personal username ID.\n3. Click the `Web Preview` icon. \n4. From the list that appears, select `Change port`.\n5. Enter the new port number: 9870.\n6. Select `Change and Preview`.\n","dateUpdated":"2018-08-16T22:04:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Exercise #1 - HDFS User Interface</h2>\n<p>In this exercise, you will create a second SSH tunnel to connect to the HDFS UI. In this UI, you can see the details of the distributed storage system that your current cluster is using.</p>\n<p>To create a new SSH tunnel, follow the next steps:<br/>1. On the <code>Google Cloud Shell</code> used to execute this Zeppelin instance, click the <code>+</code> sign to <strong>Add cloud shell session</strong>.<br/>2. To create the tunnel, enter the following command:<br/><code>gcloud compute ssh --project data-castle-bravo --zone us-central1-a --ssh-flag=&quot;-L 9870:localhost:9870&quot; de-training-&lt;user-name&gt;-m</code><br/>Make sure to replace <code>&lt;user-name&gt;</code> with your personal username ID.<br/>3. Click the <code>Web Preview</code> icon.<br/>4. From the list that appears, select <code>Change port</code>.<br/>5. Enter the new port number: 9870.<br/>6. Select <code>Change and Preview</code>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588838_420763624","id":"20180815-184431_1946821920","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:435","user":"anonymous","dateFinished":"2018-08-16T22:04:49+0000","dateStarted":"2018-08-16T22:04:49+0000"},{"text":"","dateUpdated":"2018-08-16T22:04:49+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Explore the UI to answer the following questions:</h3>\n<ul>\n  <li>How many nodes does your cluster have?</li>\n  <li>How much memory has been assigned to the cluster?</li>\n  <li>How many nodes are active, and how many are dead?</li>\n  <li>How much storage capacity is remaining?</li>\n  <li>What are the cluster metrics?</li>\n</ul>\n<p><strong>TIP:</strong> If you would like to know the available memory or review your cluster’s capacities, look at the HDFS UI again after the executions.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588838_420763624","id":"20180816-043836_513971066","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:436","user":"anonymous"},{"text":"%md\n### Sockets for other UIs \nAs you may have noticed by know, the [SSH tunnel we created for Zeppelin](https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces#create_an_ssh_tunnel) is exposed on port 8080 of your clusters' master node. A [short list of the UIs](https://console.cloud.google.com/dataproc/jobs?project=data-castle-bravo) you may find available in this cluster are:\n* **Zeppelin**: localhost:8080\n* **HDFS NameNode**: localhost:9870\n\n### Exposing HDFS to Other Nodes\nTo look at each individual node, you will need to create an SSH tunnel to that particular instance and expose the pertinent port as follows:\n`gcloud compute ssh --project data-castle-bravo --zone us-central1-a --ssh-flag=\"-L 9870:localhost:9870\" de-training-<user-name>-m`\n\nMake sure to replace <user-name> with your personal username ID.\n","dateUpdated":"2018-08-16T22:04:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Sockets for other UIs</h3>\n<p>As you may have noticed by know, the <a href=\"https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces#create_an_ssh_tunnel\">SSH tunnel we created for Zeppelin</a> is exposed on port 8080 of your clusters&rsquo; master node. A <a href=\"https://console.cloud.google.com/dataproc/jobs?project=data-castle-bravo\">short list of the UIs</a> you may find available in this cluster are:<br/>* <strong>Zeppelin</strong>: localhost:8080<br/>* <strong>HDFS NameNode</strong>: localhost:9870</p>\n<h3>Exposing HDFS to Other Nodes</h3>\n<p>To look at each individual node, you will need to create an SSH tunnel to that particular instance and expose the pertinent port as follows:<br/><code>gcloud compute ssh --project data-castle-bravo --zone us-central1-a --ssh-flag=&quot;-L 9870:localhost:9870&quot; de-training-&lt;user-name&gt;-m</code></p>\n<p>Make sure to replace <user-name> with your personal username ID.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588839_420378875","id":"20180816-044001_308739423","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:437","user":"anonymous","dateFinished":"2018-08-16T22:04:49+0000","dateStarted":"2018-08-16T22:04:49+0000"},{"text":"%md\n## Exercise #2 - Matrix Multiplication\nIn this exercise, we will be exploring the `Matrix` data type. All `Matrix` implementations are another abstraction of `RDD`s.\n \n**Note**: All that you need to know about `Matrix` multiplication, will be provided to you in this notebook. \n\nPrioritize researching the functions that belong to `DataFrames` or `DataSets`, I/O Functions, or Spark Core in general over any `Matrix` method or function you wish to use. During the next three weeks you will gain knowledge about tools and information to better optimize this operation.\n\n**HINT:** The best use of your time will be to return after each subsequent session to implement improvements that optimize this code*.\n\nFirst, import the data structures you will be using during the session with the following command:\n","dateUpdated":"2018-08-16T22:04:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Exercise #2 - Matrix Multiplication</h2>\n<p>In this exercise, we will be exploring the <code>Matrix</code> data type. All <code>Matrix</code> implementations are another abstraction of <code>RDD</code>s.</p>\n<p><strong>Note</strong>: All that you need to know about <code>Matrix</code> multiplication, will be provided to you in this notebook. </p>\n<p>Prioritize researching the functions that belong to <code>DataFrames</code> or <code>DataSets</code>, I/O Functions, or Spark Core in general over any <code>Matrix</code> method or function you wish to use. During the next three weeks you will gain knowledge about tools and information to better optimize this operation.</p>\n<p><strong>HINT:</strong> The best use of your time will be to return after each subsequent session to implement improvements that optimize this code*.</p>\n<p>First, import the data structures you will be using during the session with the following command:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588839_420378875","id":"20180816-044039_285868597","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:438","user":"anonymous","dateFinished":"2018-08-16T22:04:49+0000","dateStarted":"2018-08-16T22:04:49+0000"},{"text":"import org.apache.spark.rdd.RDD\nimport org.apache.spark.mllib.linalg.distributed.{BlockMatrix, CoordinateMatrix, MatrixEntry}","dateUpdated":"2018-08-16T22:04:49+0000","config":{"tableHide":false,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.rdd.RDD\nimport org.apache.spark.mllib.linalg.distributed.{BlockMatrix, CoordinateMatrix, MatrixEntry}\n"}]},"apps":[],"jobName":"paragraph_1534456588839_420378875","id":"20180816-051038_545285622","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:440","user":"anonymous","dateFinished":"2018-08-16T22:04:50+0000","dateStarted":"2018-08-16T22:04:49+0000"},{"text":"%md\n#### Create dataset\nThe most straight forward implementation for a matrix multiplication is using a `BlockMatrix`. The [documentation](https://spark.apache.org/docs/2.3.0/mllib-data-types.html#blockmatrix) describes this type of matrix as a is **Distributed Matrix** backed by an `RDD` of `MatrixBlock`s.\n\nA `MatrixBlock` is a tuple of `((Int, Int), Matrix)`. In this context, `(Int, Int)` is the (Row, Column) position of the block while `Matrix` is the sub-matrix at the given index with size `rowsPerBlock` x `colsPerBlock`\n\nBelow you'll find the `MatrixEntry` sequences containing the location and value of each element in all matrices. \n\nCreate four RDDs with the provided sequence:\n","dateUpdated":"2018-08-16T22:04:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>Create dataset</h4>\n<p>The most straight forward implementation for a matrix multiplication is using a <code>BlockMatrix</code>. The <a href=\"https://spark.apache.org/docs/2.3.0/mllib-data-types.html#blockmatrix\">documentation</a> describes this type of matrix as a is <strong>Distributed Matrix</strong> backed by an <code>RDD</code> of <code>MatrixBlock</code>s.</p>\n<p>A <code>MatrixBlock</code> is a tuple of <code>((Int, Int), Matrix)</code>. In this context, <code>(Int, Int)</code> is the (Row, Column) position of the block while <code>Matrix</code> is the sub-matrix at the given index with size <code>rowsPerBlock</code> x <code>colsPerBlock</code></p>\n<p>Below you&rsquo;ll find the <code>MatrixEntry</code> sequences containing the location and value of each element in all matrices. </p>\n<p>Create four RDDs with the provided sequence:</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588839_420378875","id":"20180816-051039_1898536718","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:441","user":"anonymous","dateFinished":"2018-08-16T22:04:49+0000","dateStarted":"2018-08-16T22:04:49+0000"},{"text":"val green_location_value = Seq(MatrixEntry(0,0,21), MatrixEntry(1,0,23), MatrixEntry(0,1,22), MatrixEntry(1,1,24))\nval blue_location_value = Seq(MatrixEntry(0,0,11), MatrixEntry(1,0,13), MatrixEntry(0,1,12), MatrixEntry(1,1,14))\nval orange_location_value = Seq(MatrixEntry(0,0,0.4), MatrixEntry(1,0,0.2), MatrixEntry(0,1,0.3), MatrixEntry(1,1,0.1))\nval brown_location_value = Seq(MatrixEntry(0,0,4), MatrixEntry(1,0,2), MatrixEntry(0,1,3), MatrixEntry(1,1,1))\n\nval green: RDD[MatrixEntry] = sc.parallelize(green_location_value)\nval blue: RDD[MatrixEntry] = sc.parallelize(blue_location_value)\nval orange: RDD[MatrixEntry] = sc.parallelize(orange_location_value)\nval brown: RDD[MatrixEntry] = sc.parallelize(brown_location_value)","dateUpdated":"2018-08-16T22:04:49+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"green_location_value: Seq[org.apache.spark.mllib.linalg.distributed.MatrixEntry] = List(MatrixEntry(0,0,21.0), MatrixEntry(1,0,23.0), MatrixEntry(0,1,22.0), MatrixEntry(1,1,24.0))\nblue_location_value: Seq[org.apache.spark.mllib.linalg.distributed.MatrixEntry] = List(MatrixEntry(0,0,11.0), MatrixEntry(1,0,13.0), MatrixEntry(0,1,12.0), MatrixEntry(1,1,14.0))\norange_location_value: Seq[org.apache.spark.mllib.linalg.distributed.MatrixEntry] = List(MatrixEntry(0,0,0.4), MatrixEntry(1,0,0.2), MatrixEntry(0,1,0.3), MatrixEntry(1,1,0.1))\nbrown_location_value: Seq[org.apache.spark.mllib.linalg.distributed.MatrixEntry] = List(MatrixEntry(0,0,4.0), MatrixEntry(1,0,2.0), MatrixEntry(0,1,3.0), MatrixEntry(1,1,1.0))\ngreen: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.distributed.MatrixEntry] = ParallelCollectionRDD[619] at parallelize at <console>:47\nblue: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.distributed.MatrixEntry] = ParallelCollectionRDD[620] at parallelize at <console>:46\norange: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.distributed.MatrixEntry] = ParallelCollectionRDD[621] at parallelize at <console>:46\nbrown: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.distributed.MatrixEntry] = ParallelCollectionRDD[622] at parallelize at <console>:46\n"}]},"apps":[],"jobName":"paragraph_1534456588840_418455130","id":"20180816-051431_1380261728","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:442","user":"anonymous","dateFinished":"2018-08-16T22:04:53+0000","dateStarted":"2018-08-16T22:04:49+0000"},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1534456702454_464041035","id":"20180816-215822_204561953","dateCreated":"2018-08-16T21:58:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:2217","dateUpdated":"2018-08-16T22:04:50+0000","dateFinished":"2018-08-16T22:04:50+0000","dateStarted":"2018-08-16T22:04:50+0000","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong>TIP:</strong> You can create an RDD with Spark using this command:<br/><code>sc.Parallel()</code></p>\n</div>"}]},"text":"%md\n**TIP:** You can create an RDD with Spark using this command: \n`sc.Parallel()`"},{"text":"\n#### BlockMatrix creation function\nThe easiest path to create a `BlockMatrix` is by converting a `CoordinateMatrix(RDD)` using the `toMatrixBlock()`. In Scala to Create a `CoordinateMatrix`, you need an RDD of `MatrixEntry`. For Python you can use DataFrames that already are consistent with the tuple of `((Int, Int), Matrix)`.\n\nCreate a function called `create_blockMatrix` where you input a `matrix` in `dataset` format and create a Block matrix from the dataset's RDD representation (`dataset.RDD`) using the function `CoordinateMatrix(<RDD>)` and method `toMatrixBlock()` mentioned before.","dateUpdated":"2018-08-16T22:04:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:44: error: not found: value ####\n       #### BlockMatrix creation function\n       ^\n<console>:44: error: not found: value creation\n       #### BlockMatrix creation function\n                        ^\n"}]},"apps":[],"jobName":"paragraph_1534456588840_418455130","id":"20180816-052746_2109723812","dateCreated":"2018-08-16T21:56:28+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:443","user":"anonymous","dateFinished":"2018-08-16T22:04:53+0000","dateStarted":"2018-08-16T22:04:50+0000"},{"text":"def create_blockMatrix(matrixEntries: RDD[MatrixEntry]) = {\n    new CoordinateMatrix(matrixEntries).toBlockMatrix()\n}\n","dateUpdated":"2018-08-16T22:04:50+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"create_blockMatrix: (matrixEntries: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.distributed.MatrixEntry])org.apache.spark.mllib.linalg.distributed.BlockMatrix\n"}]},"apps":[],"jobName":"paragraph_1534456588840_418455130","id":"20180816-051640_149771352","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:444","user":"anonymous","dateFinished":"2018-08-16T22:04:54+0000","dateStarted":"2018-08-16T22:04:53+0000"},{"text":"","dateUpdated":"2018-08-16T22:04:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now apply the function <code>create_blockMatrix(RDD)</code> to generate the four block matrices, following the naming convention <code>block_&lt;color&gt;</code></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588841_418070381","id":"20180816-051434_624669525","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:445","user":"anonymous"},{"text":"val block_green: BlockMatrix = create_blockMatrix(green)\nval block_blue: BlockMatrix = create_blockMatrix(blue)\nval block_orange: BlockMatrix = create_blockMatrix(orange)\nval block_brown: BlockMatrix = create_blockMatrix(brown)","dateUpdated":"2018-08-16T22:04:50+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"block_green: org.apache.spark.mllib.linalg.distributed.BlockMatrix = org.apache.spark.mllib.linalg.distributed.BlockMatrix@55371436\nblock_blue: org.apache.spark.mllib.linalg.distributed.BlockMatrix = org.apache.spark.mllib.linalg.distributed.BlockMatrix@396e4cdd\nblock_orange: org.apache.spark.mllib.linalg.distributed.BlockMatrix = org.apache.spark.mllib.linalg.distributed.BlockMatrix@3439d422\nblock_brown: org.apache.spark.mllib.linalg.distributed.BlockMatrix = org.apache.spark.mllib.linalg.distributed.BlockMatrix@361c0976\n"}]},"apps":[],"jobName":"paragraph_1534456588841_418070381","id":"20180816-053544_199438445","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:446","user":"anonymous","dateFinished":"2018-08-16T22:04:55+0000","dateStarted":"2018-08-16T22:04:53+0000"},{"text":"","dateUpdated":"2018-08-16T22:04:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now that all matrices are <code>BlockMatrices</code> use the method <code>.multiply(&lt;block_matrix&gt;)</code> to perform the multiplication of the four matrices.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588841_418070381","id":"20180816-053542_76914317","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:447","user":"anonymous"},{"text":"val output_matrix: BlockMatrix = block_green.multiply(block_blue).multiply(block_orange).multiply(block_brown)\n\noutput_matrix.toLocalMatrix()","dateUpdated":"2018-08-16T22:04:50+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"output_matrix: org.apache.spark.mllib.linalg.distributed.BlockMatrix = org.apache.spark.mllib.linalg.distributed.BlockMatrix@f0b98aa\nres31: org.apache.spark.mllib.linalg.Matrix =\n1697.4  1167.5\n1855.0  1275.8999999999999\n"}]},"apps":[],"jobName":"paragraph_1534456588841_418070381","id":"20180816-054044_1121238451","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:448","user":"anonymous","dateFinished":"2018-08-16T22:04:56+0000","dateStarted":"2018-08-16T22:04:54+0000"},{"text":"","dateUpdated":"2018-08-16T22:04:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Finally to store this information in your output bucket you use:<br/>Make sure to replace <code>&lt;user-name&gt;</code> with your personal username ID.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588841_418070381","id":"20180816-051040_524958004","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:449","user":"anonymous"},{"text":"val bucket = \"gs://de-training-output-<user-name>/matrix-multiplication-exercise-result\"\noutput_matrix.toCoordinateMatrix().entries.saveAsTextFile(bucket)","dateUpdated":"2018-08-16T22:04:50+0000","config":{"tableHide":true,"editorSetting":{"language":"scala"},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"bucket: String = gs://de-training-output-<user-name>/matrix-multiplication-exercise-result\njava.lang.IllegalArgumentException: Invalid bucket name (de-training-output-<user-name>) or object name ()\n  at com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:99)\n  at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.configureBuckets(GoogleHadoopFileSystem.java:75)\n  at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(GoogleHadoopFileSystemBase.java:2011)\n  at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1102)\n  at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.initialize(GoogleHadoopFileSystemBase.java:1065)\n  at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2812)\n  at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:100)\n  at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2849)\n  at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2831)\n  at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:389)\n  at org.apache.hadoop.fs.Path.getFileSystem(Path.java:356)\n  at org.apache.spark.internal.io.SparkHadoopWriterUtils$.createPathFromString(SparkHadoopWriterUtils.scala:55)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1069)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1035)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:961)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:961)\n  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:961)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:960)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1489)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1468)\n  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1468)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\n  at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1468)\n  ... 48 elided\nCaused by: java.net.URISyntaxException: Illegal character in authority at index 5: gs://de-training-output-<user-name>/\n  at java.net.URI$Parser.fail(URI.java:2848)\n  at java.net.URI$Parser.parseAuthority(URI.java:3186)\n  at java.net.URI$Parser.parseHierarchical(URI.java:3097)\n  at java.net.URI$Parser.parse(URI.java:3053)\n  at java.net.URI.<init>(URI.java:588)\n  at com.google.cloud.hadoop.gcsio.LegacyPathCodec.getPath(LegacyPathCodec.java:93)\n  ... 80 more\n"}]},"apps":[],"jobName":"paragraph_1534456588842_419224628","id":"20180816-055550_1811176051","dateCreated":"2018-08-16T21:56:28+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:450","user":"anonymous","dateFinished":"2018-08-16T22:04:57+0000","dateStarted":"2018-08-16T22:04:55+0000"},{"text":"%md\n**Note:** we are converting the `BlockMatrix` back to `CoordinateMatrix` for writing purposes.","dateUpdated":"2018-08-16T22:04:50+0000","config":{"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong>Note:</strong> we are converting the <code>BlockMatrix</code> back to <code>CoordinateMatrix</code> for writing purposes.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588842_419224628","id":"20180816-055549_596649276","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:451","user":"anonymous","dateFinished":"2018-08-16T22:04:51+0000","dateStarted":"2018-08-16T22:04:51+0000"},{"text":"%md\n## Exercise #3 - Matrix Multiplication\n\nFind the result of the multiplication of each squared matrix. \n\nThis statement requires you to square each matrix, and then multiply them together. So we need to do something as follows:\ngreen^2 * blue^2 * orange^2 * brown^2\n\nYou have already implemented a multiplication, now implement a function for exponents.\n\nName the function `matrix_exponent`. This function recieves `integer` (non-zero and positive) and a `BlockMatrix`as parameters for the exponent.\n\n**NOTE:**: This is the perfect opportinuty to practice recursion and your functional programming skills.\n","dateUpdated":"2018-08-16T22:04:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Exercise #3 - Matrix Multiplication</h2>\n<p>Find the result of the multiplication of each squared matrix. </p>\n<p>This statement requires you to square each matrix, and then multiply them together. So we need to do something as follows:<br/>green^2 * blue^2 * orange^2 * brown^2</p>\n<p>You have already implemented a multiplication, now implement a function for exponents.</p>\n<p>Name the function <code>matrix_exponent</code>. This function recieves <code>integer</code> (non-zero and positive) and a <code>BlockMatrix</code>as parameters for the exponent.</p>\n<p><strong>NOTE:</strong>: This is the perfect opportinuty to practice recursion and your functional programming skills.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588842_419224628","id":"20180816-055812_104119781","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:452","user":"anonymous","dateFinished":"2018-08-16T22:04:51+0000","dateStarted":"2018-08-16T22:04:51+0000"},{"text":" def matrix_exponent(exponent: Int, matrixToMultiply: BlockMatrix): BlockMatrix = {\n    var matrix: BlockMatrix = matrixToMultiply\n    if (exponent == 1) matrix\n    else matrix.multiply(matrix_exponent(exponent-1, matrix))\n  }\n","dateUpdated":"2018-08-16T22:04:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala","editOnDblClick":false}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"matrix_exponent: (exponent: Int, matrixToMultiply: org.apache.spark.mllib.linalg.distributed.BlockMatrix)org.apache.spark.mllib.linalg.distributed.BlockMatrix\n"}]},"apps":[],"jobName":"paragraph_1534456588842_419224628","id":"20180816-055548_1870600573","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:453","user":"anonymous","dateFinished":"2018-08-16T22:04:57+0000","dateStarted":"2018-08-16T22:04:56+0000"},{"text":"%md\nBefore going further, test this with the Green Matrix. Compare the result of your function with the succesive multiplication for a few exponents (2,3,1)","dateUpdated":"2018-08-16T22:04:51+0000","config":{"editorSetting":{"language":"text","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/text","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1534456588842_419224628","id":"20180816-061052_1535624378","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:454","user":"anonymous","dateFinished":"2018-08-16T22:04:51+0000","dateStarted":"2018-08-16T22:04:51+0000"},{"text":"val exponent:BlockMatrix = matrix_exponent(2,block_green)\nexponent.blocks.collect()","dateUpdated":"2018-08-16T22:04:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"exponent: org.apache.spark.mllib.linalg.distributed.BlockMatrix = org.apache.spark.mllib.linalg.distributed.BlockMatrix@630ae2fd\nres33: Array[((Int, Int), org.apache.spark.mllib.linalg.Matrix)] =\nArray(((0,0),947.0   990.0\n1035.0  1082.0  ))\n"}]},"apps":[],"jobName":"paragraph_1534456588843_418839879","id":"20180816-060847_989894645","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:455","user":"anonymous","dateFinished":"2018-08-16T22:04:58+0000","dateStarted":"2018-08-16T22:04:57+0000"},{"text":"%md\nFinally, use the `matrix_exponent` function along with the `multiply(<block_matrix>)` method to calculate *the sequential multiplication of each squared matrix*.","dateUpdated":"2018-08-16T22:04:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Finally, use the <code>matrix_exponent</code> function along with the <code>multiply(&lt;block_matrix&gt;)</code> method to calculate <em>the sequential multiplication of each squared matrix</em>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588843_418839879","id":"20180816-060216_68421027","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:456","user":"anonymous","dateFinished":"2018-08-16T22:04:51+0000","dateStarted":"2018-08-16T22:04:51+0000"},{"text":"\n\nval exercise2: BlockMatrix = matrix_exponent(2,block_green).multiply(matrix_exponent(2,block_blue)).multiply(matrix_exponent(2,block_orange)).multiply(matrix_exponent(2,block_brown))\nexercise2.blocks.collect()","dateUpdated":"2018-08-16T22:04:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/scala","results":{},"enabled":true,"editorSetting":{"language":"scala"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"exercise2: org.apache.spark.mllib.linalg.distributed.BlockMatrix = org.apache.spark.mllib.linalg.distributed.BlockMatrix@189a1925\nres36: Array[((Int, Int), org.apache.spark.mllib.linalg.Matrix)] =\nArray(((0,0),5537479.460000001  3799534.3500000006\n6052062.900000001  4152615.1100000013  ))\n"}]},"apps":[],"jobName":"paragraph_1534456588843_418839879","id":"20180816-061358_1587903354","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:457","user":"anonymous","dateFinished":"2018-08-16T22:05:00+0000","dateStarted":"2018-08-16T22:04:57+0000"},{"text":"%md\n**Congratulations for completing the exercises!**\nDo spend some time thinking of other possible improvements for your code on your own time, such as how to make the matrix_exponent respond to fractions, 0, and other types of input","dateUpdated":"2018-08-16T22:04:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><strong>Congratulations for completing the exercises!</strong><br/>Do spend some time thinking of other possible improvements for your code on your own time, such as how to make the matrix_exponent respond to fractions, 0, and other types of input</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1534456588843_418839879","id":"20180816-060215_1568828441","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:458","user":"anonymous","dateFinished":"2018-08-16T22:04:51+0000","dateStarted":"2018-08-16T22:04:51+0000"},{"text":"%md\n","dateUpdated":"2018-08-16T22:04:51+0000","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true}},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1534456588843_418839879","id":"20180816-061612_1285669371","dateCreated":"2018-08-16T21:56:28+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:459","user":"anonymous"}],"name":"Matrix-Multiplication-Exercises-Scala","id":"2DPDH92FP","angularObjects":{"2DPV5GYZV:shared_process":[],"2DMXVEND8:shared_process":[],"2DP2JZ1T7:shared_process":[],"2DMQCTGAC:shared_process":[],"2DPT2WPZN:shared_process":[],"2DMAE54WY:shared_process":[],"2DMJQGHDP:shared_process":[],"2DQXFTHN6:shared_process":[],"2DNHU9QDY:shared_process":[],"2DPC2RS1N:shared_process":[],"2DMMWEW7N:shared_process":[],"2DNSBFHYA:shared_process":[],"2DPPW98XB:shared_process":[],"2DP8U9D6K:shared_process":[],"2DN67JH1V:shared_process":[],"2DNHYRTT8:shared_process":[],"2DMJY7M94:shared_process":[],"2DQQ5WYPM:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}